{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install CuPy that matches Colab's CUDA 12.x\n",
        "# IMPORTANT: After this finishes, restart the session in runtime\n",
        "%pip -q install -U cupy-cuda12x\n"
      ],
      "metadata": {
        "id": "7ZA4YxGEpnkB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "\n",
        "import os\n",
        "print(\"CUDA_VISIBLE_DEVICES =\", os.environ.get(\"CUDA_VISIBLE_DEVICES\"))\n",
        "\n",
        "import cupy as cp\n",
        "print(\"CuPy version:\", cp.__version__)\n",
        "print(\"CuPy device count:\", cp.cuda.runtime.getDeviceCount())\n",
        "cp.cuda.Device(0).use()\n",
        "x = cp.arange(5)\n",
        "print(\"CuPy test tensor on\", x.device, \"->\", x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3PraJdAqVOo",
        "outputId": "9ab498c3-c3a9-471d-db29-83323f679cf3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct 23 07:17:55 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "CUDA_VISIBLE_DEVICES = None\n",
            "CuPy version: 13.6.0\n",
            "CuPy device count: 1\n",
            "CuPy test tensor on <CUDA Device 0> -> [0 1 2 3 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We are using record and get the time dynamically\n",
        "TIMINGS = {}\n",
        "\n",
        "def record_time(name, seconds):\n",
        "    TIMINGS[name] = float(seconds)\n",
        "\n",
        "def get_time(name, default=None):\n",
        "    return TIMINGS.get(name, default)\n",
        "\n",
        "def fmt(s):\n",
        "    try: return f\"{float(s):.2f}\"\n",
        "    except: return \"N/A\"\n"
      ],
      "metadata": {
        "id": "1otcXI_cq4zd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3 Layer Nueral Network implementation using  Keras**"
      ],
      "metadata": {
        "id": "LyWWEUrL7agI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "IfJW3bsJ6lnG",
        "outputId": "96844f7a-6cde-4297-ea63-fc7b161fc058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Keras Model Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Keras model on CPU...\n",
            "Keras Training Time (CPU): 25.12 seconds\n",
            "Keras Test Accuracy (CPU): 0.9778\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Ensure TensorFlow uses only the CPU\n",
        "# (Changed: use TF API so CuPy can still see the GPU in other cells)\n",
        "try:\n",
        "    tf.config.set_visible_devices([], 'GPU')\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# 1. Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# 2. Define the 3-layer Neural Network model\n",
        "# Input: 28x28 images flattened to 784 features\n",
        "# Hidden Layer: 128 neurons, ReLU activation\n",
        "# Output Layer: 10 neurons (for 10 classes), softmax activation\n",
        "model_keras = keras.Sequential([\n",
        "    keras.Input(shape=(28, 28)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation=\"relu\", name=\"hidden_layer\"),\n",
        "    layers.Dense(10, activation=\"softmax\", name=\"output_layer\")\n",
        "])\n",
        "\n",
        "# Display the model summary\n",
        "print(\"Keras Model Summary:\")\n",
        "model_keras.summary()\n",
        "\n",
        "# 3. Compile the model\n",
        "model_keras.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# 4. Train the model and measure time\n",
        "print(\"\\nTraining Keras model on CPU...\")\n",
        "start_time_keras = time.time()\n",
        "history_keras = model_keras.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=64,\n",
        "    epochs=10,\n",
        "    validation_split=0.2,\n",
        "    verbose=0 # Suppress verbose output during training\n",
        ")\n",
        "keras_training_time = time.time() - start_time_keras\n",
        "record_time(\"keras_cpu\", keras_training_time)\n",
        "print(f\"Keras Training Time (CPU): {keras_training_time:.2f} seconds\")\n",
        "\n",
        "# 5. Evaluate the model on the test data\n",
        "test_loss_keras, test_accuracy_keras = model_keras.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Keras Test Accuracy (CPU): {test_accuracy_keras:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3 Layer Nueral network using Numpy implementation**"
      ],
      "metadata": {
        "id": "dHNomDNo68NI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "# Re-load and preprocess data for NumPy model (flatten directly)\n",
        "(x_train_np, y_train_np), (x_test_np, y_test_np) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize and flatten images\n",
        "x_train_np = x_train_np.reshape(x_train_np.shape[0], -1).astype(\"float32\") / 255.0\n",
        "x_test_np  = x_test_np.reshape(x_test_np.shape[0], -1).astype(\"float32\") / 255.0\n",
        "\n",
        "# One-hot encode labels for cross-entropy calculation\n",
        "def one_hot_encode(labels, num_classes):\n",
        "    return np.eye(num_classes, dtype=np.float32)[labels]\n",
        "\n",
        "y_train_one_hot = one_hot_encode(y_train_np, 10)\n",
        "y_test_one_hot  = one_hot_encode(y_test_np, 10)\n",
        "\n",
        "# Neural Network Architecture Parameters\n",
        "input_size = 784\n",
        "hidden_size = 128\n",
        "output_size = 10\n",
        "learning_rate = 0.01\n",
        "epochs_np = 10\n",
        "batch_size_np = 64\n",
        "\n",
        "# Initialize weights and biases\n",
        "np.random.seed(42) # for reproducibility\n",
        "weights_input_hidden  = (np.random.randn(input_size, hidden_size).astype(np.float32) * 0.01)\n",
        "bias_hidden           = np.zeros((1, hidden_size), dtype=np.float32)\n",
        "weights_hidden_output = (np.random.randn(hidden_size, output_size).astype(np.float32) * 0.01)\n",
        "bias_output           = np.zeros((1, output_size), dtype=np.float32)\n",
        "\n",
        "# Activation Functions\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "    return (x > 0).astype(np.float32)\n",
        "\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True)) # for numerical stability\n",
        "    return exp_x / (np.sum(exp_x, axis=1, keepdims=True) + 1e-12)\n",
        "\n",
        "# Loss Function: Categorical Cross-Entropy\n",
        "def categorical_crossentropy(predictions, targets):\n",
        "    num_samples = predictions.shape[0]\n",
        "    predictions = np.clip(predictions, 1e-12, 1. - 1e-12)\n",
        "    return float(-np.sum(targets * np.log(predictions)) / num_samples)\n",
        "\n",
        "# Training Loop\n",
        "print(\"\\nTraining NumPy model (from scratch)...\")\n",
        "start_time_np = time.time()\n",
        "\n",
        "for epoch in range(epochs_np):\n",
        "    # Shuffle training data for each epoch\n",
        "    permutation = np.random.permutation(x_train_np.shape[0])\n",
        "    x_train_shuffled = x_train_np[permutation]\n",
        "    y_train_shuffled = y_train_one_hot[permutation]\n",
        "\n",
        "    for i in range(0, x_train_np.shape[0], batch_size_np):\n",
        "        x_batch = x_train_shuffled[i:i+batch_size_np]\n",
        "        y_batch = y_train_shuffled[i:i+batch_size_np]\n",
        "\n",
        "        # Forward Propagation\n",
        "        # Layer 1 (Input to Hidden)\n",
        "        z1 = np.dot(x_batch, weights_input_hidden) + bias_hidden\n",
        "        a1 = relu(z1)\n",
        "\n",
        "        # Layer 2 (Hidden to Output)\n",
        "        z2 = np.dot(a1, weights_hidden_output) + bias_output\n",
        "        a2 = softmax(z2) # Output probabilities\n",
        "\n",
        "        # Backward Propagation\n",
        "        dz2 = a2 - y_batch # Derivative of cross-entropy with softmax\n",
        "\n",
        "        d_weights_hidden_output = np.dot(a1.T, dz2)\n",
        "        d_bias_output = np.sum(dz2, axis=0, keepdims=True)\n",
        "\n",
        "        da1 = np.dot(dz2, weights_hidden_output.T)\n",
        "        dz1 = da1 * relu_derivative(z1)\n",
        "\n",
        "        d_weights_input_hidden = np.dot(x_batch.T, dz1)\n",
        "        d_bias_hidden = np.sum(dz1, axis=0, keepdims=True)\n",
        "\n",
        "        # Update Weights and Biases (SGD)\n",
        "        weights_hidden_output -= learning_rate * d_weights_hidden_output\n",
        "        bias_output          -= learning_rate * d_bias_output\n",
        "        weights_input_hidden -= learning_rate * d_weights_input_hidden\n",
        "        bias_hidden          -= learning_rate * d_bias_hidden\n",
        "\n",
        "numpy_training_time = time.time() - start_time_np\n",
        "record_time(\"numpy_from_scratch_cpu\", numpy_training_time)\n",
        "print(f\"NumPy Training Time (from scratch): {numpy_training_time:.2f} seconds\")\n",
        "\n",
        "# Evaluate NumPy model\n",
        "z1_test = np.dot(x_test_np, weights_input_hidden) + bias_hidden\n",
        "a1_test = relu(z1_test)\n",
        "z2_test = np.dot(a1_test, weights_hidden_output) + bias_output\n",
        "a2_test = softmax(z2_test)\n",
        "\n",
        "predictions_np = np.argmax(a2_test, axis=1)\n",
        "accuracy_np = np.mean(predictions_np == y_test_np)\n",
        "print(f\"NumPy Test Accuracy (from scratch): {accuracy_np:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSB7ZWAt6vqi",
        "outputId": "35ad43ba-ad4d-4f9a-9bc9-618b6ec7dcdb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training NumPy model (from scratch)...\n",
            "NumPy Training Time (from scratch): 7.79 seconds\n",
            "NumPy Test Accuracy (from scratch): 0.9776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**comparison of  keras and Numpy implemenation speed-up **"
      ],
      "metadata": {
        "id": "fov04qKb7H9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\n--- Speed-Up Analysis ---\")\n",
        "print(f\"Keras Training Time (CPU): {keras_training_time:.2f} seconds\")\n",
        "print(f\"NumPy Training Time (from scratch): {numpy_training_time:.2f} seconds\")\n",
        "\n",
        "if numpy_training_time > 0:\n",
        "    speed_up = numpy_training_time / keras_training_time\n",
        "    print(f\"Speed-up of Keras (CPU) over NumPy (from scratch): {speed_up:.2f}x\")\n",
        "else:\n",
        "    print(\"NumPy training time was zero, cannot calculate speed-up.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ehle21Y6-Pn",
        "outputId": "754511e4-e09b-4354-d1c2-dc9b646dd9b0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Speed-Up Analysis ---\n",
            "Keras Training Time (CPU): 25.12 seconds\n",
            "NumPy Training Time (from scratch): 7.79 seconds\n",
            "Speed-up of Keras (CPU) over NumPy (from scratch): 0.31x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tiling for Matrix multiplication**"
      ],
      "metadata": {
        "id": "SjYCgIdl7Ili"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def naive_matrix_multiply(A, B):\n",
        "    \"\"\"Naive matrix multiplication without any optimizations.\"\"\"\n",
        "    rows_A, cols_A = A.shape\n",
        "    rows_B, cols_B = B.shape\n",
        "    if cols_A != rows_B:\n",
        "        raise ValueError(\"Matrices A and B cannot be multiplied.\")\n",
        "\n",
        "    C = np.zeros((rows_A, cols_B))\n",
        "    for i in range(rows_A):\n",
        "        for j in range(cols_B):\n",
        "            for k in range(cols_A):\n",
        "                C[i, j] += A[i, k] * B[k, j]\n",
        "    return C\n",
        "\n",
        "def tiled_matrix_multiply(A, B, block_size):\n",
        "    \"\"\"Matrix multiplication with tiling optimization.\"\"\"\n",
        "    rows_A, cols_A = A.shape\n",
        "    rows_B, cols_B = B.shape\n",
        "    if cols_A != rows_B:\n",
        "        raise ValueError(\"Matrices A and B cannot be multiplied.\")\n",
        "\n",
        "    C = np.zeros((rows_A, cols_B))\n",
        "\n",
        "    for i1 in range(0, rows_A, block_size):\n",
        "        for j1 in range(0, cols_B, block_size):\n",
        "            for k1 in range(0, cols_A, block_size):\n",
        "                # Process block\n",
        "                for i in range(i1, min(i1 + block_size, rows_A)):\n",
        "                    for j in range(j1, min(j1 + block_size, cols_B)):\n",
        "                        for k in range(k1, min(k1 + block_size, cols_A)):\n",
        "                            C[i, j] += A[i, k] * B[k, j]\n",
        "    return C\n",
        "\n",
        "# Generate large random matrices for benchmarking\n",
        "matrix_size = 256 # For demonstration, choose a size that runs in reasonable time\n",
        "A = np.random.rand(matrix_size, matrix_size)\n",
        "B = np.random.rand(matrix_size, matrix_size)\n",
        "block_size = 32 # Example block size\n",
        "\n",
        "print(f\"\\n--- Matrix Multiplication Benchmarking (Size: {matrix_size}x{matrix_size}) ---\")\n",
        "\n",
        "# Benchmark Naive\n",
        "start_time = time.time()\n",
        "C_naive = naive_matrix_multiply(A, B)\n",
        "time_naive = time.time() - start_time\n",
        "print(f\"Naive matrix multiply time: {time_naive:.4f} seconds\")\n",
        "\n",
        "# Benchmark Tiled\n",
        "start_time = time.time()\n",
        "C_tiled = tiled_matrix_multiply(A, B, block_size)\n",
        "time_tiled = time.time() - start_time\n",
        "print(f\"Tiled matrix multiply (block={block_size}) time: {time_tiled:.4f} seconds\")\n",
        "\n",
        "# Benchmark NumPy's optimized dot\n",
        "start_time = time.time()\n",
        "C_np = np.dot(A, B)\n",
        "time_np = time.time() - start_time\n",
        "print(f\"NumPy np.dot time: {time_np:.4f} seconds\")\n",
        "\n",
        "# Verify correctness (optional)\n",
        "# print(f\"Are naive and numpy results close? {np.allclose(C_naive, C_np)}\")\n",
        "# print(f\"Are tiled and numpy results close? {np.allclose(C_tiled, C_np)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uk0jX--s7HEH",
        "outputId": "78a2fedc-21d4-4681-d653-d23db4b7f702"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Matrix Multiplication Benchmarking (Size: 256x256) ---\n",
            "Naive matrix multiply time: 10.7569 seconds\n",
            "Tiled matrix multiply (block=32) time: 10.6417 seconds\n",
            "NumPy np.dot time: 0.0030 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**GPU Implementation of 3 layer NN**"
      ],
      "metadata": {
        "id": "2WAb3K_o-GL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Attempt to import CuPy\n",
        "try:\n",
        "    import cupy as cp\n",
        "    print(\"CuPy imported successfully.\")\n",
        "    _has_cuda = False\n",
        "    try:\n",
        "        _has_cuda = cp.cuda.runtime.getDeviceCount() > 0\n",
        "    except Exception:\n",
        "        pass\n",
        "    if _has_cuda:\n",
        "        print(\"CUDA GPU is available and detected by CuPy.\")\n",
        "        array_lib = cp\n",
        "        cp.cuda.Device(0).use()\n",
        "    else:\n",
        "        print(\"CUDA GPU not available. Falling back to NumPy (CPU).\")\n",
        "        array_lib = np\n",
        "except ImportError:\n",
        "    print(\"CuPy not installed. Falling back to NumPy (CPU).\")\n",
        "    array_lib = np\n",
        "\n",
        "# Keep TensorFlow off GPU so it doesn't block CuPy\n",
        "try:\n",
        "    tf.config.set_visible_devices([], 'GPU')\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# Load MNIST\n",
        "(x_train_np, y_train_np), (x_test_np, y_test_np) = keras.datasets.mnist.load_data()\n",
        "x_train_np = x_train_np.reshape(x_train_np.shape[0], -1).astype(\"float32\") / 255.0\n",
        "x_test_np = x_test_np.reshape(x_test_np.shape[0], -1).astype(\"float32\") / 255.0\n",
        "\n",
        "# One-hot encode\n",
        "def one_hot_encode(labels, num_classes):\n",
        "    return np.eye(num_classes)[labels]\n",
        "y_train_one_hot_np = one_hot_encode(y_train_np, 10)\n",
        "y_test_one_hot_np = one_hot_encode(y_test_np, 10)\n",
        "\n",
        "# Transfer data\n",
        "x_train = array_lib.asarray(x_train_np)\n",
        "y_train_one_hot = array_lib.asarray(y_train_one_hot_np)\n",
        "x_test = array_lib.asarray(x_test_np)\n",
        "y_test = array_lib.asarray(y_test_np)\n",
        "\n",
        "# Network params\n",
        "input_size, hidden_size, output_size = 784, 128, 10\n",
        "learning_rate, epochs, batch_size = 0.01, 10, 128\n",
        "\n",
        "# Init weights\n",
        "array_lib.random.seed(42)\n",
        "W1 = array_lib.random.randn(input_size, hidden_size) * 0.01\n",
        "b1 = array_lib.zeros((1, hidden_size))\n",
        "W2 = array_lib.random.randn(hidden_size, output_size) * 0.01\n",
        "b2 = array_lib.zeros((1, output_size))\n",
        "\n",
        "# Activation funcs\n",
        "def relu(x): return array_lib.maximum(0, x)\n",
        "def relu_derivative(x): return (x > 0).astype(array_lib.float32)\n",
        "def softmax(x):\n",
        "    exp_x = array_lib.exp(x - array_lib.max(x, axis=1, keepdims=True))\n",
        "    return exp_x / array_lib.sum(exp_x, axis=1, keepdims=True)\n",
        "\n",
        "def cross_entropy(pred, target):\n",
        "    pred = array_lib.clip(pred, 1e-12, 1. - 1e-12)\n",
        "    return -array_lib.sum(target * array_lib.log(pred)) / pred.shape[0]\n",
        "\n",
        "print(f\"\\nTraining from-scratch model on {'GPU' if array_lib.__name__=='cupy' else 'CPU'}...\")\n",
        "start = time.time()\n",
        "\n",
        "for ep in range(epochs):\n",
        "    idx = np.random.permutation(x_train.shape[0])\n",
        "    x_shuf = x_train[array_lib.asarray(idx)]\n",
        "    y_shuf = y_train_one_hot[array_lib.asarray(idx)]\n",
        "\n",
        "    for i in range(0, x_train.shape[0], batch_size):\n",
        "        xb, yb = x_shuf[i:i+batch_size], y_shuf[i:i+batch_size]\n",
        "        z1 = array_lib.dot(xb, W1) + b1\n",
        "        a1 = relu(z1)\n",
        "        z2 = array_lib.dot(a1, W2) + b2\n",
        "        a2 = softmax(z2)\n",
        "\n",
        "        dz2 = a2 - yb\n",
        "        dW2 = array_lib.dot(a1.T, dz2)\n",
        "        db2 = array_lib.sum(dz2, axis=0, keepdims=True)\n",
        "        da1 = array_lib.dot(dz2, W2.T)\n",
        "        dz1 = da1 * relu_derivative(z1)\n",
        "        dW1 = array_lib.dot(xb.T, dz1)\n",
        "        db1 = array_lib.sum(dz1, axis=0, keepdims=True)\n",
        "\n",
        "        W2 -= learning_rate * dW2\n",
        "        b2 -= learning_rate * db2\n",
        "        W1 -= learning_rate * dW1\n",
        "        b1 -= learning_rate * db1\n",
        "\n",
        "    if ep % 2 == 0:\n",
        "        loss = cross_entropy(a2, yb)\n",
        "        print(f\"Epoch {ep+1}/{epochs}, Loss: {float(loss.get() if hasattr(loss,'get') else loss):.4f}\")\n",
        "\n",
        "gpu_training_time = time.time() - start\n",
        "record_time(\"from_scratch_gpu\", gpu_training_time)\n",
        "print(f\"Training time: {gpu_training_time:.2f}s\")\n",
        "\n",
        "# Test\n",
        "z1 = array_lib.dot(x_test, W1) + b1\n",
        "a1 = relu(z1)\n",
        "z2 = array_lib.dot(a1, W2) + b2\n",
        "a2 = softmax(z2)\n",
        "\n",
        "pred = array_lib.argmax(a2, axis=1)\n",
        "pred = pred.get() if hasattr(pred, \"get\") else pred\n",
        "acc = np.mean(pred == y_test_np)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdCgqnqgsTxs",
        "outputId": "29808cf4-d814-42d4-84b3-17a5e6960fe1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CuPy imported successfully.\n",
            "CUDA GPU is available and detected by CuPy.\n",
            "\n",
            "Training from-scratch model on GPU...\n",
            "Epoch 1/10, Loss: 0.2479\n",
            "Epoch 3/10, Loss: 0.1511\n",
            "Epoch 5/10, Loss: 0.1115\n",
            "Epoch 7/10, Loss: 0.0740\n",
            "Epoch 9/10, Loss: 0.0240\n",
            "Training time: 5.55s\n",
            "Test Accuracy: 0.9686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_t   = get_time(\"from_scratch_gpu\")\n",
        "numpy_t = get_time(\"numpy_from_scratch_cpu\")\n",
        "keras_t = get_time(\"keras_cpu\")\n",
        "\n",
        "print(\"\\n--- Speed-Up Analysis (dynamic, measured) ---\")\n",
        "print(f\"NumPy (CPU):   {fmt(numpy_t)} s\")\n",
        "print(f\"Keras (CPU):   {fmt(keras_t)} s\")\n",
        "print(f\"CuPy (GPU):    {fmt(gpu_t)} s\")\n",
        "\n",
        "if gpu_t:\n",
        "    if numpy_t:\n",
        "        print(f\"Speed-up GPU vs NumPy CPU: {numpy_t / gpu_t:.2f}x\")\n",
        "    if keras_t:\n",
        "        print(f\"Speed-up GPU vs Keras CPU: {keras_t / gpu_t:.2f}x\")\n",
        "else:\n",
        "    print(\"Run GPU cell first to record its timing.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5jBtQZCr6k5",
        "outputId": "32a1be2d-35e2-432f-d2db-29cd9a856e13"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Speed-Up Analysis (dynamic, measured) ---\n",
            "NumPy (CPU):   7.79 s\n",
            "Keras (CPU):   25.12 s\n",
            "CuPy (GPU):    5.55 s\n",
            "Speed-up GPU vs NumPy CPU: 1.40x\n",
            "Speed-up GPU vs Keras CPU: 4.53x\n"
          ]
        }
      ]
    }
  ]
}