{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**3 Layer Nueral Network implementation using  Keras**"
      ],
      "metadata": {
        "id": "LyWWEUrL7agI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "IfJW3bsJ6lnG",
        "outputId": "c2f506ea-e29f-43b3-92e8-f2408fcac594"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Keras Model Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Keras model on CPU...\n",
            "Keras Training Time (CPU): 18.47 seconds\n",
            "Keras Test Accuracy (CPU): 0.9724\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Ensure TensorFlow uses only the CPU\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "\n",
        "# 1. Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# 2. Define the 3-layer Neural Network model\n",
        "# Input: 28x28 images flattened to 784 features\n",
        "# Hidden Layer: 128 neurons, ReLU activation\n",
        "# Output Layer: 10 neurons (for 10 classes), softmax activation\n",
        "model_keras = keras.Sequential([\n",
        "    keras.Input(shape=(28, 28)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation=\"relu\", name=\"hidden_layer\"),\n",
        "    layers.Dense(10, activation=\"softmax\", name=\"output_layer\")\n",
        "])\n",
        "\n",
        "# Display the model summary\n",
        "print(\"Keras Model Summary:\")\n",
        "model_keras.summary()\n",
        "\n",
        "# 3. Compile the model\n",
        "model_keras.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# 4. Train the model and measure time\n",
        "print(\"\\nTraining Keras model on CPU...\")\n",
        "start_time_keras = time.time()\n",
        "history_keras = model_keras.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=64,\n",
        "    epochs=5, # Reduced epochs for faster comparison\n",
        "    validation_split=0.2,\n",
        "    verbose=0 # Suppress verbose output during training\n",
        ")\n",
        "end_time_keras = time.time()\n",
        "keras_training_time = end_time_keras - start_time_keras\n",
        "print(f\"Keras Training Time (CPU): {keras_training_time:.2f} seconds\")\n",
        "\n",
        "# 5. Evaluate the model on the test data\n",
        "test_loss_keras, test_accuracy_keras = model_keras.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Keras Test Accuracy (CPU): {test_accuracy_keras:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3 Layer Nueral network using Numpy implementation**"
      ],
      "metadata": {
        "id": "dHNomDNo68NI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-load and preprocess data for NumPy model (flatten directly)\n",
        "(x_train_np, y_train_np), (x_test_np, y_test_np) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize and flatten images\n",
        "x_train_np = x_train_np.reshape(x_train_np.shape[0], -1).astype(\"float32\") / 255.0\n",
        "x_test_np = x_test_np.reshape(x_test_np.shape[0], -1).astype(\"float32\") / 255.0\n",
        "\n",
        "# One-hot encode labels for cross-entropy calculation\n",
        "def one_hot_encode(labels, num_classes):\n",
        "    return np.eye(num_classes)[labels]\n",
        "\n",
        "y_train_one_hot = one_hot_encode(y_train_np, 10)\n",
        "y_test_one_hot = one_hot_encode(y_test_np, 10)\n",
        "\n",
        "# Neural Network Architecture Parameters\n",
        "input_size = 784\n",
        "hidden_size = 128\n",
        "output_size = 10\n",
        "learning_rate = 0.01\n",
        "epochs_np = 5 # Reduced epochs for faster comparison\n",
        "batch_size_np = 64\n",
        "\n",
        "# Initialize weights and biases\n",
        "np.random.seed(42) # for reproducibility\n",
        "weights_input_hidden = np.random.randn(input_size, hidden_size) * 0.01\n",
        "bias_hidden = np.zeros((1, hidden_size))\n",
        "weights_hidden_output = np.random.randn(hidden_size, output_size) * 0.01\n",
        "bias_output = np.zeros((1, output_size))\n",
        "\n",
        "# Activation Functions\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "    return (x > 0).astype(float)\n",
        "\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True)) # for numerical stability\n",
        "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "\n",
        "# Loss Function: Categorical Cross-Entropy\n",
        "def categorical_crossentropy(predictions, targets):\n",
        "    num_samples = predictions.shape[0]\n",
        "    # Clip predictions to avoid log(0)\n",
        "    predictions = np.clip(predictions, 1e-12, 1. - 1e-12)\n",
        "    loss = -np.sum(targets * np.log(predictions)) / num_samples\n",
        "    return loss\n",
        "\n",
        "# Training Loop\n",
        "print(\"\\nTraining NumPy model (from scratch)...\")\n",
        "start_time_np = time.time()\n",
        "\n",
        "for epoch in range(epochs_np):\n",
        "    # Shuffle training data for each epoch\n",
        "    permutation = np.random.permutation(x_train_np.shape[0])\n",
        "    x_train_shuffled = x_train_np[permutation]\n",
        "    y_train_shuffled = y_train_one_hot[permutation]\n",
        "\n",
        "    for i in range(0, x_train_np.shape[0], batch_size_np):\n",
        "        x_batch = x_train_shuffled[i:i+batch_size_np]\n",
        "        y_batch = y_train_shuffled[i:i+batch_size_np]\n",
        "\n",
        "        # Forward Propagation\n",
        "        # Layer 1 (Input to Hidden)\n",
        "        z1 = np.dot(x_batch, weights_input_hidden) + bias_hidden\n",
        "        a1 = relu(z1)\n",
        "\n",
        "        # Layer 2 (Hidden to Output)\n",
        "        z2 = np.dot(a1, weights_hidden_output) + bias_output\n",
        "        a2 = softmax(z2) # Output probabilities\n",
        "\n",
        "        # Backward Propagation\n",
        "        # Output Layer (dL/da2 * da2/dz2)\n",
        "        # Gradient of loss w.r.t. z2\n",
        "        dz2 = a2 - y_batch # Derivative of cross-entropy with softmax\n",
        "\n",
        "        # Gradients for weights_hidden_output and bias_output\n",
        "        d_weights_hidden_output = np.dot(a1.T, dz2)\n",
        "        d_bias_output = np.sum(dz2, axis=0, keepdims=True)\n",
        "\n",
        "        # Hidden Layer (dL/da1 * da1/dz1)\n",
        "        # Gradient of loss w.r.t. a1\n",
        "        da1 = np.dot(dz2, weights_hidden_output.T)\n",
        "        # Gradient of loss w.r.t. z1\n",
        "        dz1 = da1 * relu_derivative(z1)\n",
        "\n",
        "        # Gradients for weights_input_hidden and bias_hidden\n",
        "        d_weights_input_hidden = np.dot(x_batch.T, dz1)\n",
        "        d_bias_hidden = np.sum(dz1, axis=0, keepdims=True)\n",
        "\n",
        "        # Update Weights and Biases (SGD)\n",
        "        weights_hidden_output -= learning_rate * d_weights_hidden_output\n",
        "        bias_output -= learning_rate * d_bias_output\n",
        "        weights_input_hidden -= learning_rate * d_weights_input_hidden\n",
        "        bias_hidden -= learning_rate * d_bias_hidden\n",
        "\n",
        "end_time_np = time.time()\n",
        "numpy_training_time = end_time_np - start_time_np\n",
        "print(f\"NumPy Training Time (from scratch): {numpy_training_time:.2f} seconds\")\n",
        "\n",
        "# Evaluate NumPy model\n",
        "# Forward pass for test data\n",
        "z1_test = np.dot(x_test_np, weights_input_hidden) + bias_hidden\n",
        "a1_test = relu(z1_test)\n",
        "z2_test = np.dot(a1_test, weights_hidden_output) + bias_output\n",
        "a2_test = softmax(z2_test)\n",
        "\n",
        "predictions_np = np.argmax(a2_test, axis=1)\n",
        "accuracy_np = np.mean(predictions_np == y_test_np)\n",
        "print(f\"NumPy Test Accuracy (from scratch): {accuracy_np:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSB7ZWAt6vqi",
        "outputId": "43e05c79-9534-4a76-d00b-dae2a5b1d5b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training NumPy model (from scratch)...\n",
            "NumPy Training Time (from scratch): 8.58 seconds\n",
            "NumPy Test Accuracy (from scratch): 0.9750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**comparison of  keras and Numpy implemenation speed-up **"
      ],
      "metadata": {
        "id": "fov04qKb7H9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\n--- Speed-Up Analysis ---\")\n",
        "print(f\"Keras Training Time (CPU): {keras_training_time:.2f} seconds\")\n",
        "print(f\"NumPy Training Time (from scratch): {numpy_training_time:.2f} seconds\")\n",
        "\n",
        "if numpy_training_time > 0:\n",
        "    speed_up = numpy_training_time / keras_training_time\n",
        "    print(f\"Speed-up of Keras (CPU) over NumPy (from scratch): {speed_up:.2f}x\")\n",
        "else:\n",
        "    print(\"NumPy training time was zero, cannot calculate speed-up.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ehle21Y6-Pn",
        "outputId": "4c1cd663-ae40-442c-acec-9e1910511232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Speed-Up Analysis ---\n",
            "Keras Training Time (CPU): 18.47 seconds\n",
            "NumPy Training Time (from scratch): 8.58 seconds\n",
            "Speed-up of Keras (CPU) over NumPy (from scratch): 0.46x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tiling for Matrix multiplication**"
      ],
      "metadata": {
        "id": "SjYCgIdl7Ili"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def naive_matrix_multiply(A, B):\n",
        "    \"\"\"Naive matrix multiplication without any optimizations.\"\"\"\n",
        "    rows_A, cols_A = A.shape\n",
        "    rows_B, cols_B = B.shape\n",
        "    if cols_A != rows_B:\n",
        "        raise ValueError(\"Matrices A and B cannot be multiplied.\")\n",
        "\n",
        "    C = np.zeros((rows_A, cols_B))\n",
        "    for i in range(rows_A):\n",
        "        for j in range(cols_B):\n",
        "            for k in range(cols_A):\n",
        "                C[i, j] += A[i, k] * B[k, j]\n",
        "    return C\n",
        "\n",
        "def tiled_matrix_multiply(A, B, block_size):\n",
        "    \"\"\"Matrix multiplication with tiling optimization.\"\"\"\n",
        "    rows_A, cols_A = A.shape\n",
        "    rows_B, cols_B = B.shape\n",
        "    if cols_A != rows_B:\n",
        "        raise ValueError(\"Matrices A and B cannot be multiplied.\")\n",
        "\n",
        "    C = np.zeros((rows_A, cols_B))\n",
        "\n",
        "    for i1 in range(0, rows_A, block_size):\n",
        "        for j1 in range(0, cols_B, block_size):\n",
        "            for k1 in range(0, cols_A, block_size):\n",
        "                # Process block\n",
        "                for i in range(i1, min(i1 + block_size, rows_A)):\n",
        "                    for j in range(j1, min(j1 + block_size, cols_B)):\n",
        "                        for k in range(k1, min(k1 + block_size, cols_A)):\n",
        "                            C[i, j] += A[i, k] * B[k, j]\n",
        "    return C\n",
        "\n",
        "# Generate large random matrices for benchmarking\n",
        "matrix_size = 256 # For demonstration, choose a size that runs in reasonable time\n",
        "A = np.random.rand(matrix_size, matrix_size)\n",
        "B = np.random.rand(matrix_size, matrix_size)\n",
        "block_size = 32 # Example block size\n",
        "\n",
        "print(f\"\\n--- Matrix Multiplication Benchmarking (Size: {matrix_size}x{matrix_size}) ---\")\n",
        "\n",
        "# Benchmark Naive\n",
        "start_time = time.time()\n",
        "C_naive = naive_matrix_multiply(A, B)\n",
        "time_naive = time.time() - start_time\n",
        "print(f\"Naive matrix multiply time: {time_naive:.4f} seconds\")\n",
        "\n",
        "# Benchmark Tiled\n",
        "start_time = time.time()\n",
        "C_tiled = tiled_matrix_multiply(A, B, block_size)\n",
        "time_tiled = time.time() - start_time\n",
        "print(f\"Tiled matrix multiply (block={block_size}) time: {time_tiled:.4f} seconds\")\n",
        "\n",
        "# Benchmark NumPy's optimized dot\n",
        "start_time = time.time()\n",
        "C_np = np.dot(A, B)\n",
        "time_np = time.time() - start_time\n",
        "print(f\"NumPy np.dot time: {time_np:.4f} seconds\")\n",
        "\n",
        "# Verify correctness (optional)\n",
        "# print(f\"Are naive and numpy results close? {np.allclose(C_naive, C_np)}\")\n",
        "# print(f\"Are tiled and numpy results close? {np.allclose(C_tiled, C_np)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uk0jX--s7HEH",
        "outputId": "dfec20a7-21bc-4a25-cad5-06a2cb9dc0f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Matrix Multiplication Benchmarking (Size: 256x256) ---\n",
            "Naive matrix multiply time: 12.5226 seconds\n",
            "Tiled matrix multiply (block=32) time: 12.6191 seconds\n",
            "NumPy np.dot time: 0.0022 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GPU Implementation of 3 layer NN**"
      ],
      "metadata": {
        "id": "2WAb3K_o-GL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install cupy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmcEVQ3O-P1H",
        "outputId": "89f0093b-9ad6-4a78-e2c9-9bd3f97af35e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cupy\n",
            "  Downloading cupy-13.6.0.tar.gz (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<2.6,>=1.22 in /usr/local/lib/python3.12/dist-packages (from cupy) (2.0.2)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.12/dist-packages (from cupy) (0.8.3)\n",
            "Building wheels for collected packages: cupy\n",
            "  Building wheel for cupy (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cupy: filename=cupy-13.6.0-cp312-cp312-linux_x86_64.whl size=95231240 sha256=e78ff5db28912c32cbce0656cbee28c1d12e84bd721df62306e21e8de3623c5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/62/e2/466b4487b8c7ef9b9345937b46481dd5a58c67252ccd828c75\n",
            "Successfully built cupy\n",
            "Installing collected packages: cupy\n",
            "Successfully installed cupy-13.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf # Used only for loading MNIST data\n",
        "from tensorflow import keras\n",
        "\n",
        "# Attempt to import CuPy and check for GPU availability\n",
        "try:\n",
        "    import cupy as cp\n",
        "    print(\"CuPy imported successfully.\")\n",
        "    if cp.cuda.is_available():\n",
        "        print(\"CUDA GPU is available and detected by CuPy.\")\n",
        "        # Set the default array library to CuPy for convenience\n",
        "        array_lib = cp\n",
        "        # Set default device to GPU (optional, CuPy uses it by default if available)\n",
        "        cp.cuda.Device(0).use()\n",
        "    else:\n",
        "        print(\"CUDA GPU not available. Falling back to NumPy (CPU).\")\n",
        "        array_lib = np\n",
        "except ImportError:\n",
        "    print(\"CuPy not installed. Falling back to NumPy (CPU). Install CuPy for GPU acceleration.\")\n",
        "    array_lib = np\n",
        "\n",
        "# Ensure TensorFlow uses only the CPU for data loading if CuPy is used\n",
        "# This prevents TensorFlow from potentially grabbing GPU resources before CuPy\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "\n",
        "# 1. Load and preprocess the MNIST dataset using TensorFlow/Keras\n",
        "(x_train_np, y_train_np), (x_test_np, y_test_np) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize and flatten images\n",
        "x_train_np = x_train_np.reshape(x_train_np.shape[0], -1).astype(\"float32\") / 255.0\n",
        "x_test_np = x_test_np.reshape(x_test_np.shape[0], -1).astype(\"float32\") / 255.0\n",
        "\n",
        "# One-hot encode labels for cross-entropy calculation\n",
        "def one_hot_encode(labels, num_classes):\n",
        "    return np.eye(num_classes)[labels] # Use NumPy for one-hot encoding on CPU first\n",
        "\n",
        "y_train_one_hot_np = one_hot_encode(y_train_np, 10)\n",
        "y_test_one_hot_np = one_hot_encode(y_test_np, 10)\n",
        "\n",
        "# 2. Transfer data to GPU (if CuPy is active)\n",
        "# If array_lib is cp, these will be CuPy arrays on GPU\n",
        "# Otherwise, they remain NumPy arrays on CPU\n",
        "x_train = array_lib.asarray(x_train_np)\n",
        "y_train_one_hot = array_lib.asarray(y_train_one_hot_np)\n",
        "x_test = array_lib.asarray(x_test_np)\n",
        "y_test = array_lib.asarray(y_test_np) # Keep y_test_np for final comparison, as array_lib is for operations\n",
        "\n",
        "# Neural Network Architecture Parameters\n",
        "input_size = 784\n",
        "hidden_size = 128\n",
        "output_size = 10\n",
        "learning_rate = 0.01\n",
        "epochs_gpu = 10 # More epochs for better accuracy if GPU is fast\n",
        "batch_size_gpu = 128 # Larger batch size often beneficial on GPU\n",
        "\n",
        "# Initialize weights and biases directly on the GPU (if CuPy)\n",
        "array_lib.random.seed(42) # for reproducibility\n",
        "weights_input_hidden = array_lib.random.randn(input_size, hidden_size) * 0.01\n",
        "bias_hidden = array_lib.zeros((1, hidden_size))\n",
        "weights_hidden_output = array_lib.random.randn(hidden_size, output_size) * 0.01\n",
        "bias_output = array_lib.zeros((1, output_size))\n",
        "\n",
        "# Activation Functions (using array_lib, which will be cp or np)\n",
        "def relu(x):\n",
        "    return array_lib.maximum(0, x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "    return (x > 0).astype(array_lib.float32) # Ensure type consistency\n",
        "\n",
        "def softmax(x):\n",
        "    # for numerical stability (CuPy's max is like NumPy's)\n",
        "    exp_x = array_lib.exp(x - array_lib.max(x, axis=1, keepdims=True))\n",
        "    return exp_x / array_lib.sum(exp_x, axis=1, keepdims=True)\n",
        "\n",
        "# Loss Function: Categorical Cross-Entropy\n",
        "def categorical_crossentropy(predictions, targets):\n",
        "    num_samples = predictions.shape[0]\n",
        "    # Clip predictions to avoid log(0)\n",
        "    predictions = array_lib.clip(predictions, 1e-12, 1. - 1e-12)\n",
        "    loss = -array_lib.sum(targets * array_lib.log(predictions)) / num_samples\n",
        "    return loss\n",
        "\n",
        "# Training Loop\n",
        "print(f\"\\nTraining from-scratch model on { 'GPU' if array_lib is cp else 'CPU' }...\")\n",
        "start_time_gpu = time.time()\n",
        "\n",
        "for epoch in range(epochs_gpu):\n",
        "    # Shuffle training data for each epoch\n",
        "    # Create permutation on CPU, then transfer indices to GPU\n",
        "    permutation_indices = np.random.permutation(x_train.shape[0])\n",
        "    # Use CuPy's advanced indexing\n",
        "    x_train_shuffled = x_train[array_lib.asarray(permutation_indices)]\n",
        "    y_train_shuffled = y_train_one_hot[array_lib.asarray(permutation_indices)]\n",
        "\n",
        "    for i in range(0, x_train.shape[0], batch_size_gpu):\n",
        "        x_batch = x_train_shuffled[i:i+batch_size_gpu]\n",
        "        y_batch = y_train_shuffled[i:i+batch_size_gpu]\n",
        "\n",
        "        # Forward Propagation\n",
        "        z1 = array_lib.dot(x_batch, weights_input_hidden) + bias_hidden\n",
        "        a1 = relu(z1)\n",
        "\n",
        "        z2 = array_lib.dot(a1, weights_hidden_output) + bias_output\n",
        "        a2 = softmax(z2)\n",
        "\n",
        "        # Backward Propagation\n",
        "        dz2 = a2 - y_batch\n",
        "\n",
        "        d_weights_hidden_output = array_lib.dot(a1.T, dz2)\n",
        "        d_bias_output = array_lib.sum(dz2, axis=0, keepdims=True)\n",
        "\n",
        "        da1 = array_lib.dot(dz2, weights_hidden_output.T)\n",
        "        dz1 = da1 * relu_derivative(z1)\n",
        "\n",
        "        d_weights_input_hidden = array_lib.dot(x_batch.T, dz1)\n",
        "        d_bias_hidden = array_lib.sum(dz1, axis=0, keepdims=True)\n",
        "\n",
        "        # Update Weights and Biases (SGD)\n",
        "        weights_hidden_output -= learning_rate * d_weights_hidden_output\n",
        "        bias_output -= learning_rate * d_bias_output\n",
        "        weights_input_hidden -= learning_rate * d_weights_input_hidden\n",
        "        bias_hidden -= learning_rate * d_bias_hidden\n",
        "\n",
        "    # Optional: Print loss/accuracy per epoch to monitor progress\n",
        "    if epoch % 2 == 0:\n",
        "        # Calculate loss on a small validation set or full training set\n",
        "        # For simplicity, let's just calculate training loss\n",
        "        z1_train = array_lib.dot(x_train, weights_input_hidden) + bias_hidden\n",
        "        a1_train = relu(z1_train)\n",
        "        z2_train = array_lib.dot(a1_train, weights_hidden_output) + bias_output\n",
        "        a2_train = softmax(z2_train)\n",
        "        train_loss = categorical_crossentropy(a2_train, y_train_one_hot)\n",
        "        print(f\"Epoch {epoch+1}/{epochs_gpu}, Train Loss: {train_loss:.4f}\")\n",
        "\n",
        "\n",
        "end_time_gpu = time.time()\n",
        "gpu_training_time = end_time_gpu - start_time_gpu\n",
        "print(f\"From-scratch training time on { 'GPU' if array_lib is cp else 'CPU' }: {gpu_training_time:.2f} seconds\")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "# Forward pass for test data\n",
        "z1_test = array_lib.dot(x_test, weights_input_hidden) + bias_hidden\n",
        "a1_test = relu(z1_test)\n",
        "z2_test = array_lib.dot(a1_test, weights_hidden_output) + bias_output\n",
        "a2_test = softmax(z2_test)\n",
        "\n",
        "# Move predictions back to CPU for comparison with NumPy y_test_np\n",
        "predictions_gpu = array_lib.argmax(a2_test, axis=1).get() # .get() moves CuPy array to NumPy array on CPU\n",
        "accuracy_gpu = np.mean(predictions_gpu == y_test_np)\n",
        "print(f\"From-scratch Test Accuracy on { 'GPU' if array_lib is cp else 'CPU' }: {accuracy_gpu:.4f}\")\n",
        "\n",
        "# --- Speed-Up Analysis (requires running the previous Keras and NumPy CPU codes) ---\n",
        "# Assuming you have `keras_training_time` and `numpy_training_time` from previous runs\n",
        "# For demonstration purposes, let's define dummy values if not run\n",
        " keras_training_time = 12.0 # Replace with actual\n",
        " numpy_training_time = 200.0 # Replace with actual\n",
        "\n",
        " print(f\"\\n--- Speed-Up Analysis ---\")\n",
        " print(f\"Keras Training Time (CPU): {keras_training_time:.2f} seconds\")\n",
        " print(f\"NumPy Training Time (from scratch, CPU): {numpy_training_time:.2f} seconds\")\n",
        " print(f\"From-scratch Training Time ({ 'GPU' if array_lib is cp else 'CPU' }): {gpu_training_time:.2f} seconds\")\n",
        "\n",
        " if array_lib is cp:\n",
        "     if numpy_training_time > 0:\n",
        "         speed_up_gpu_over_numpy_cpu = numpy_training_time / gpu_training_time\n",
        "         print(f\"Speed-up of From-scratch GPU over From-scratch NumPy (CPU): {speed_up_gpu_over_numpy_cpu:.2f}x\")\n",
        "     if keras_training_time > 0:\n",
        "         speed_up_gpu_over_keras_cpu = keras_training_time / gpu_training_time\n",
        "         print(f\"Speed-up of From-scratch GPU over Keras (CPU): {speed_up_gpu_over_keras_cpu:.2f}x\")\n",
        " else:\n",
        "     print(\"GPU not available, cannot calculate GPU speed-up.\")\n"
      ],
      "metadata": {
        "id": "_TMjZkLS-Fd9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}